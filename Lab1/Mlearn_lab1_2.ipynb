{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhO7z3QosT4Q"
      },
      "source": [
        "# **Machine Learning from Data**\n",
        "\n",
        "## Lab 1: MAP and Gaussian data - Part 2\n",
        "\n",
        "2021 - 2023 - Veronica Vilaplana - [GPI @ IDEAI](https://imatge.upc.edu/web/) Research group\n",
        "\n",
        "-----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7zNKFaufACm"
      },
      "source": [
        "##Classification criteria based on maximizing the posterior probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1qJ7DDzfED8"
      },
      "source": [
        "##Part2: Eigenvalues of the covariance matrix and cluster shape\n",
        "In this second part we will work with the QPSK modulation. Therefore, we have a classification problem with four classes and two features per class.\n",
        "\n",
        "We will consider two cases: covariances of all classes identical but arbitrary (case 2 studied in class) and different covariant matrices(case 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ8J_MO9Z1-W"
      },
      "source": [
        "import pandas as pd             #import pandas with the alias pd\n",
        "import numpy as np              #import numpy with the alias np\n",
        "import seaborn as sns           #import seaborn with the alias sns\n",
        "import scipy.stats as ss\n",
        "import matplotlib.pyplot as plt #import matplotlib.pyplot with the alias plt\n",
        "from numpy.random import default_rng\n",
        "# initialize a random seed such that every execution will raise same random sequences of results\n",
        "rng = default_rng(seed=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "novCrxBfskEM"
      },
      "source": [
        "#1. Data generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HURhQ_4jsqaE"
      },
      "source": [
        "###Parameter initialization\n",
        "\n",
        "The parameter $\\sigma$ will be derived from the desired SNR, given as input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4FIGO8Df6y1"
      },
      "source": [
        "# Input a SNR value:\n",
        "SNR = 10\n",
        "#SNR = 5\n",
        "\n",
        "# Design parameters\n",
        "dist=1.                # distance between classes mean\n",
        "n_classes = 4          # number of classes\n",
        "n_samples = 1000;      # number of samples per class\n",
        "n_feat = 2             # number of features per class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2KPE2n-f7Y-"
      },
      "source": [
        "To switch between case 2 and case 3, comment or un-comment the following lines\n",
        "\n",
        "In each case, you can change the value of `ro`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_rOSFjwgL-P"
      },
      "source": [
        "ro = [0, 0, 0, 0 ]          # CASE 2\n",
        "#ro = [0.5, 0.5, 0.5, 0.5]  # CASE 2\n",
        "#ro=[0.5, 0, -0.5, 0.8]     # CASE 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Yri4xZbu1H"
      },
      "source": [
        " # M_Means matrix containing the QPSK mean vectors\n",
        "M_Means = 0.5 * dist * np.array([[1, 1],[1, -1], [-1, 1], [-1,-1]])\n",
        "\n",
        "# Energy computation\n",
        "energy = 0\n",
        "for i in range(0,n_classes):\n",
        "  energy = energy + np.dot(M_Means[i],M_Means[i])\n",
        "energy = energy / n_classes\n",
        "\n",
        "# Noise variance computation\n",
        "SNR = 10 ** (SNR/10)\n",
        "sig = energy / SNR\n",
        "#sig = sig / n_feat\n",
        "\n",
        "M_covar = np.zeros(shape=(4,2,2))\n",
        "sigma = sig * np.array([1,1,1,1])\n",
        "for i in range(0,n_classes):\n",
        "  M_covar[i,:,:] = sigma[i] / n_feat * np.array([[1, ro[i]],[ro[i],1]])\n",
        "\n",
        "print(sigma)\n",
        "print(M_covar)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZJqK5ASiXOi"
      },
      "source": [
        "###Dataset generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD98kViziSfB"
      },
      "source": [
        "# Dataset Generation\n",
        "# labels is a 1D array with 0-1 int labels\n",
        "# xdata is a 2D array (columns = features, rows= samples) with random numbers\n",
        "xdata = np.empty((0,n_feat), float)\n",
        "labels = np.empty((0), int)\n",
        "for i in range(0,n_classes):\n",
        "  ydata = rng.multivariate_normal(mean=M_Means[i,:], cov= M_covar[i,:,:], size= n_samples)\n",
        "  ylabels = i * np.ones((n_samples),dtype=int)\n",
        "  xdata = np.append(xdata, ydata, axis=0)\n",
        "  labels = np.append(labels, ylabels, axis=0)\n",
        "\n",
        "# shuffle data (xdata and labels, same order)\n",
        "rp = np.random.permutation(len(xdata))\n",
        "xdatas = xdata[rp]\n",
        "xlabs  = labels[rp]\n",
        "\n",
        "print(np.shape(xdatas))\n",
        "print(np.shape(xlabs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVizwZ64ixLt"
      },
      "source": [
        "###Scatter plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDA-xIG7iShY"
      },
      "source": [
        "# 2D scatter plot (not interactive in colab!)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "#ax = fig.add_subplot(111, projection='3d')\n",
        "col = ['tab:blue','tab:orange','tab:red','tab:green']\n",
        "for idclass in range(0, n_classes):\n",
        "  idx = xlabs==idclass\n",
        "  plt.scatter(xdatas[idx,0], xdatas[idx,1], color = col[idclass], label='class %d' %idclass,alpha=0.5);\n",
        "\n",
        "plt.title(\"simple 2D scatter plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1i0GeISk9xl"
      },
      "source": [
        "#2. LDA and QDA Classifiers\n",
        "We fit the models and evaluate them on the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRUWE0FIiSkQ"
      },
      "source": [
        "# Create a linear discriminant analysis classifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "X_train = xdatas\n",
        "y_train = xlabs\n",
        "\n",
        "# Linear Discriminant Analysis\n",
        "lda = LinearDiscriminantAnalysis(solver=\"svd\",store_covariance=True)\n",
        "ldamodel = lda.fit(X_train, y_train)\n",
        "y_tpred_lda = ldamodel.predict(X_train)\n",
        "\n",
        "print('LDA model priors:',ldamodel.priors_)\n",
        "print('LDA model means:',ldamodel.means_)\n",
        "print('LDA models covariance:', ldamodel.covariance_)\n",
        "\n",
        "\n",
        "linear_error = 1. - accuracy_score(y_train,y_tpred_lda)\n",
        "print('LDA error: %f' %linear_error)\n",
        "print('LDA confusion matrix:')\n",
        "print(confusion_matrix(y_train,y_tpred_lda))\n",
        "\n",
        "\n",
        "# Quadratic Discriminant Analysis\n",
        "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
        "qdamodel = qda.fit(X_train, y_train)\n",
        "y_tpred_qda = qdamodel.predict(X_train)\n",
        "\n",
        "print('QDA model priors:',qdamodel.priors_)\n",
        "print('QDA model means:',qdamodel.means_)\n",
        "print('QDA models covariances:', qdamodel.covariance_)\n",
        "\n",
        "qda_error = 1. - accuracy_score(y_train,y_tpred_qda)\n",
        "print('QDA error: %f' %qda_error)\n",
        "print('QDA confusion matrix:')\n",
        "print(confusion_matrix(y_train,y_tpred_qda))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEhtXEJENR9i"
      },
      "source": [
        "### Decision boundaries for the lineal model\n",
        "For the lineal classifier we can plot the decision boundaries.\n",
        "In a multiclass problem like this, this is a one vs. all classifier, so hyperplanes show the boundary between each class agaist all the others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndJ5-NntRK2W"
      },
      "source": [
        "# coef_ : shape of (n_classes, n_features)\n",
        "# intercept_ :  shape of (n_classes,)\n",
        "\n",
        "# Plot the hyperplanes: one vs all\n",
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "\n",
        "col = ['tab:blue','tab:orange','tab:green','tab:red']\n",
        "\n",
        "for l,c, m in zip(np.unique(y_train),col,['s','x','o','+']):\n",
        "    plt.scatter(X_train[y_train==l,0],\n",
        "                X_train[y_train==l,1],\n",
        "                c=c, marker=m,label='class %d' %l, alpha=0.5)\n",
        "# marker=m\n",
        "x1 = np.array([np.min(X_train[:,0], axis=0), np.max(X_train[:,0], axis=0)])\n",
        "\n",
        "# lines for class 0\n",
        "for i, c in enumerate(col):\n",
        "    b, w1, w2 = lda.intercept_[i], lda.coef_[i][0], lda.coef_[i][1]\n",
        "    y1 = -(b+x1*w1)/w2\n",
        "    plt.plot(x1,y1,c=c)\n",
        "\n",
        "plt.title(\"Scatter plot with decision boundaries\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwQMKIR2fgOI"
      },
      "source": [
        "###Plotting decision regions\n",
        "We can make a different plot, where we classify all points on a 2D region around the sample data (labels are presented with different colors) and show a scatter plot of the sample (labels represented with different colors).\n",
        "\n",
        "We make this plot for the linear and for the quadratic models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsjlgKGGqNlS"
      },
      "source": [
        "# For the lineal model\n",
        "\n",
        "X = X_train\n",
        "y = y_train\n",
        "h = .001 # step size in the mesh\n",
        "\n",
        "\n",
        "col = ['tab:blue','tab:orange','tab:green','tab:red']\n",
        "#for idclass in range(0, n_classes):\n",
        "#  idx = xlabs==idclass\n",
        "#  plt.scatter(xdatas[idx,0], xdatas[idx,1], color = col[idclass], label='class %d' %idclass,alpha=0.5);\n",
        "\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "\n",
        "Z = lda.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "#plt.contourf(xx, yy, Z, colors = col, alpha=0.5)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.tab10, alpha=0.2)\n",
        "\n",
        "# Plot also the training points\n",
        "#plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
        "for idclass in range(0, n_classes):\n",
        "  idx = xlabs==idclass\n",
        "  plt.scatter(xdatas[idx,0], xdatas[idx,1], color = col[idclass], label='class %d' %idclass,alpha=0.5);\n",
        "\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.title('LDA boundaries')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R__7ciNijVKj"
      },
      "source": [
        "# For the quadratic model\n",
        "\n",
        "X = X_train\n",
        "y = y_train\n",
        "h = .001 # step size in the mesh\n",
        "\n",
        "\n",
        "col = ['tab:blue','tab:orange','tab:green','tab:red']\n",
        "#for idclass in range(0, n_classes):\n",
        "#  idx = xlabs==idclass\n",
        "#  plt.scatter(xdatas[idx,0], xdatas[idx,1], color = col[idclass], label='class %d' %idclass,alpha=0.5);\n",
        "\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10,10))\n",
        "\n",
        "Z = qda.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "#plt.contourf(xx, yy, Z, colors = col, alpha=0.5)\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.tab10, alpha=0.2)\n",
        "\n",
        "# Plot also the training points\n",
        "#plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
        "for idclass in range(0, n_classes):\n",
        "  idx = xlabs==idclass\n",
        "  plt.scatter(xdatas[idx,0], xdatas[idx,1], color = col[idclass], label='class %d' %idclass,alpha=0.5);\n",
        "\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.title('QDA boundaries')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}